---
title: "COVID-19 Government Response Event Dataset (CoronaNet v1.0)"
header-includes:
   - \usepackage{lineno}
   - \linenumbers
csl: nature.csl
author: 
  -  Cindy Cheng: 
      email: cindy.cheng@hfp.tum.de
      institute: tum
      correspondence: true
  - Joan Barceló:
      institute: nyuad
  - Allison Spencer Hartnett:
      institute: yale
  - Robert Kubinec:
      institute: nyuad
  - Luca Messerschmidt:
      institute: tum
institute:
  - tum: Hochschule für Politik at the Technical University of Munich (TUM) and the TUM School of Governance, Munich, Germany
  - nyuad: Social Science Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates
  - yale: Department of Political Science, Yale University, New Haven, United States
date: "May 31st, 2020"
toc: false
bibliography: BibTexDatabase.bib
always_allow_html: yes
output: 
 # bookdown::word_document2
  bookdown::pdf_document2:
    keep_tex: true
    latex_engine: xelatex
    includes:
      in_header:
          preamble.tex
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
urlcolor: blue
mask: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,message=FALSE,tinytex.verbose = TRUE)

# to compile with pandoc
# do brew install pandoc pandoc-citeproc
# then add this line to a .Renviron file in the project folder:
# PATH="/usr/local/Cellar/pandoc/2.9.2.1/bin/:${PATH}"

require(dplyr)
require(tidyr)
require(ggplot2)
require(lubridate)
require(stringr)
require(kableExtra)
require(rstan)
require(ggrepel)
library(readr)
library(knitr)
library(readxl)
require(gghighlight)
require(patchwork)
library(devtools)
library(igraph)
library(remotes)
#remotes::install_github("wjrl/RBioFabric")
library(RBioFabric)
library(tidygraph)
library(ggraph)
library(ggsci)
library("scales")
'%!in%' <- function(x,y)!('%in%'(x,y))

# let's load some data!
# run RCode/cleanData/cleanQualtrics_short.R

clean_data <- read.csv("../../data/CoronaNet/coronanet_release.csv", stringsAsFactors = FALSE) %>% 
   mutate(date_announced=as.Date(date_announced, '%Y-%m-%d'),
          date_start=as.Date(date_start, '%Y-%m-%d')) %>% 
  # filter(date_announced<(today()-days(5)),!is.na(country),is.na(init_other),is.na(target_other) | target_other=="")
  filter(!is.na(country),is.na(target_other)| target_other=="")%>%
  filter(type %!in% c('Hygiene', "Anti-Disinformation Measures", "Quarantine/Lockdown", "Lockdown" ))
 
# run /RCode/slack/slackAnalytics.R"

#slack <- readRDS("../data/slack/corona_govt_response_slack_latest_clean.rds")

# run /RCode/country_regions.R
regions_df = read.csv( "../../data/regions/country_regional_groups_concordance.csv", stringsAsFactors = FALSE)
countries = read.csv('../../data/regions/all_countries.csv', stringsAsFactors = FALSE)
```


\newpage
# Abstract {-}
Governments worldwide have implemented countless policies in response to the COVID-19 pandemic. We present an initial public release of a large hand-coded dataset of over 13,000 such policy announcements across more than 195 countries. The dataset is updated daily, with a 5-day lag for validity checking. We document policies across numerous dimensions, including the type of policy; national vs. sub-national enforcement; the specific human group and geographic region targeted by the policy; and the time frame within which each policy is implemented. We further analyze the dataset using a Bayesian measurement model which shows the quick acceleration of the adoption of costly policies across countries beginning in mid-March and continuing to the present. We believe that the data will be instrumental for helping policy makers and researchers assess, among other objectives, how effective different policies are in addressing the spread and health outcomes of COVID-19.

# Introduction {-}
Governments all around the world have implemented a substantial number and variety of policies in reaction to the COVID-19 pandemic over a period of a few months. However, policy makers and researchers have to date lacked access to the quality, up-to-date data they need for conducting rigorous analyses of whether, how, and to what degree these fast changing policies have worked in brunting the health, political and economic effects of the pandemic. To address this concern, in this paper, we present the CoronaNet COVID-19 Government Response Event Dataset, which provides fine-grained, monadic and dyadic data on policy actions taken by governments across the world since the Chinese government first reported the COVID-19 outbreak on December 31, 2019. At the time of writing, the dataset covers the policy actions of `r length(unique(clean_data$country))` countries up until `r max(clean_data$date_announced,na.rm=T)`, for a total of `r length(unique(clean_data$record_id))` events. 

With the help of a team of over 260 research assistants in 18 time zones, we are releasing the data on a daily basis. We are implementing a five-day lag between data collection and release to evaluate and validate ongoing coding efforts for random samples of the data to ensure the best possible quality given the considerable time constraints. More specifically, the CoronaNet dataset collects daily data on government policy actions taken in response to COVID-19 across the following dimensions:

+ The type of government policy implemented (e.g. quarantine, closure of schools  [16 total])
+ The level of government initiating the action (e.g. national, provincial)
+ The geographical target of the policy action, if applicable (e.g. national, provincial, municipal)
+ The human or material target of the policy action, if applicable (e.g. travelers, masks)
+ The directionality of the policy action, if applicable (e.g. inbound, outbound, both)
+ The mechanism of travel that the policy action targets, if applicable (e.g. flights, trains)
+ The enforcement of the policy action (e.g. mandatory, voluntary)
+ The enforcer of the policy action (e.g. national government, military)
+ The timing of the policy action (e.g. date announced, date implemented)

<!-- The rapid and devastating spread of the SARS-CoV-2 virus has put in stark relief the previously invisible connections among different countries and people. Our dataset illuminates a countervailing kind of network --- it documents not only what actions governments have taken against COVID-19, but how these actions have targeted other geographical regions and the people and resources within them over time. The data, which is publicly available, will allow us to understand among other things, how the effectiveness of different government policies may vary over time or depending on policy actions taken by other governments.  -->

Though government responses to the COVID-19 pandemic have inaugurated considerable changes in how billions of people live their lives, they draw on the lessons learned from the long history of pandemics and epidemics that came before. Indeed, the earliest written sources document how ancient Mesopotamians responded to the constant threat of epidemic by, on the one hand drawing on spiritual practices and on the other hand, isolating people showing the first symptoms of a disease from others. [@porter2005health, pp. 11-13;@farber2006health;@scott2017against, pp. 98] As time has marched forward, pandemics and epidemics have consistently and significantly affected the course of human history [@behbehani1983smallpox;@@duncan1996impact;@crosby2003columbian;@ziegler2013black;@jannetta2014epidemics] and governments have continued to implement a variety of policies in response.[@hatchett2007public;@shah2016pandemic;@porter2005health] Throughout it all, the collection of reliable data has helped advance collective understanding of which policies are effective in curbing the effects of a given disease outbreak. [@snow1854cholera;@paneth2004assessing] This is no trivial task. Indeed, previous research on pandemics and epidemics suggests that a policy which is effective in one context may be ineffective in another due to a whole host of potentially conditioning factors, including the pathogenesis of the particular disease [@taubenberger20061918;@kilbourne2006influenza], the characteristics of the underlying population [@farmer1996social;@van2020using;@bootsma2007effect;@hunter2007changing], and the available medical[@bandayrel2013information;@abelin2011lessons] and communication [@chew2010pandemics;@jarynowski2020attempt;@boyd2010use;@galaz2009pandemic] technology at the time.


We believe that the data presented in this paper can similarly help policy makers and researchers assess how effective different policies are in addressing the spread and health outcomes of COVID-19 [@flaxman2020]. While available research is necessarily preliminary, it suggests that which policies governments have implemented in response to COVID-19 [@ferguson2020report;@goumenou2020covid,@prem2020effect;@singh2020age], when they decided to implement them [@chen2020covid;@koo2020interventions], who they were targeted toward [@arriola2020;@yancy2020covid] and what state capacity they possessed to do so [@anwar2020covid;@corburn2020slum] have all significantly influenced how the virus has affected health outcomes both within and across different country contexts [@anderson2020will;@van2020covid;@barcelo2020voluntary], all of which is readily captured by this dataset [@buthe_etal2020;@kubinec_middleeast_2020] . Equally important is understanding why countries adopt different policies, with early analyses suggesting that institutional and political factors, e.g. the authoritarian or democratic nature of a country's institutions [@cronert2020democracy] or its level of political partisanship [@allcott2020polarization], play an important role. These findings will not only help improve the global response to the current crisis, but can also build an influential foundation of knowledge for responding to future outbreaks  [@barrett1998emerging;@miller2009signature].
 
 
Meanwhile, given the exogenous timing of the initial outbreak in Wuhan, China, government policies made in reaction to the COVID-19 pandemic constitute the single largest natural experiment in recent memory, allowing researchers to improve causal inference in any number of fields. Indeed, government reactions to the COVID-19 pandemic may forward our understanding of a wide-range of social phenomena, from the evolution of political institutions [@pierson2000increasing;@przeworski1999democracy;@svolik2012politics; @kitschelt2007patrons; @gailmard2019preventing] to the progression of economic development [@meltzer1999economic;@nunn2009importance; @kilian2009not; @noy2009macroeconomic;@correia1918pandemics] and the stability of financial markets [@kindleberger2011manias;@peckham2013economies] to say nothing of what we might learn about environmental economics [@dasgupta2002confronting; @folke2006resilience], mental health [@galea2003trends; @gifford2014environmental], disaster response [@baekkeskov2014pandemic;@boin2016politics] and disaster preparedness [@tierney2007margins;@blaikie2014risk;@burby2006hurricane]. One early analysis has already made use of our data to explore how lockdown policies affects political attitudes [@boleffect]. Other initial analyses suggest that the COVID-19 pandemic has already led to authoritarian backsliding in some countries [@luhrmann2020], unprecedented shocks to economies around the world [@coibion2020labor;@atkeson2020will;@mckibbin2020global;@fernandes2020economic], and serious negative mental health effects for millions of people [@zandifar2020iranian;@qiu2020nationwide]. While scholars have always sought to understand how large-scale historical events have shaped contemporary phenomena, modern technological tools allow us to document such events more quickly and more precisely than ever before.   


<!--
^[In the 1918 influenza pandemic for example, different cities in the United States implemented a variety of different policies to curb the epidemic [@hatchett2007public]. For a general review how societies and states have responded to pandemics in the modern era, see @shah2016pandemic.  For a general review of how ancient states and socieites have responded to pandemics and epidemics, see @porter2005health. Note that early historical guidelines for responding to epidemics can also be found in a number of early texts, e.g. the Bible contains a number of references to the use of quarantine to address the problem of leprosy including Leviticus 13:46 "As long as they have the disease they remain unclean. They must live alone; they must live outside the camp."] 
-->
Detailed documentation of such policies is all the more important given that policy choices made by one government often depend on the policy choices of other governments. The structure of the data we present in this paper allows researchers and policy-makers not only to examine monadic policy information---i.e., policies targeted to the same political unit that enacted it---but also directed, dyadic policy information---i.e., policies targeted to a political unit that is different from the unit that enacted it. The dyadic data is not limited to only capturing foreign policy dynamics, such as when country A implements a policy that affects citizens of country B, but can also document dynamics within countries, such as when central governments enact policies targeted to sub-national political entities. Given its dyadic structure, the dataset further enables critical analyses of the links and interdependencies between and within countries, including patterns of policy learning and diffusion across governments, as well as of cooperative and conflictual relationships in global crisis governance.

In what follows, we provide a description of the data, as well as an application of the data in which we model policy activity of countries over time. Using a Bayesian dynamic item-response theory model, we produce a statistically valid index that categorizes countries in terms of their responses to the pandemic, and further shows how quickly policy responses have changed over time. We document clear evidence of rapid policy diffusion of harsh measures in response to the virus. In the methodology section, we provide a thorough discussion of the methodology used  to collate the dataset, to manage the more than 260 research assistants coding this data around the world in real time and to create this index. 


# Results {-}

In this section, we first present some descriptive statistics that illustrate how government policy toward COVID-19 has varied across key variables. We then present our index for tracking how active governments have been with regard to announcing policies targeting COVID-19 across countries and over time.

## Descriptive Statistics {-}

Here we present some descriptive statistics for key variables available in the dataset. In Table 1, for each policy type we present cumulative totals for the number of policies and the number of countries which have implemented that policy, an average value for the number of countries a policy targets, and percentages in terms how stringently a policy is enforced. While, we highlight the number of targeted countries in this table, we note that our data also captures other potential geographic targets not shown in the table. For instance, it is possible for a national policy to be targeted toward one or more sub-national provinces or a provincial policy to be targeted toward one or more sub-provincial regions.

Table 1 shows that the policy most governments have implemented in reaction to COVID-19 is external border restrictions, i.e. policies that seek to limit entry or exit across different sovereign jurisdictions. We find that `r clean_data %>% filter(type == 'External Border Restrictions') %>% select(country) %>% summarize(length(unique(country)))` countries have made `r clean_data %>% filter(type == 'External Border Restrictions') %>% select(type) %>% summarize(n())` policy announcements about such restrictions since December 31, 2019. The second policy that most countries, by our count `r clean_data %>% filter(type %in% c('Closure of Schools', 'Closure and Regulation of Schools')) %>% select(country) %>% summarize(length(unique(country)))`, have implemented is 'Closure of Schools', of which we document `r clean_data %>% filter(type %in% c('Closure of Schools', 'Closure and Regulation of Schools')) %>% select(type) %>% summarize(n())` such policies. 

Meanwhile, the policy that has been implemented the most number of times, at `r clean_data %>% filter(type == 'Health Resources') %>% summarize(n())`, has been health resources, that is policies which seek to secure the availability of health-related materials (e.g. masks), infrastructure (e.g. hospitals) or personnel (e.g. doctors) to address the pandemic. The next most common policy in terms of the number of times it has been implemented, at `r clean_data %>% filter(type %in% c('Restriction of Non-Essential Businesses', 'Restriction and Regulation of Businesses')) %>% summarize(n())`, are policies which impose restrictions on non-essential businesses. 

However, we note that a strict comparison of policy types by this metric is not perfect, given that, for example, there may be a need for more individualized policies regarding external border restrictions (given the number of countries which a government can restrict travel access to) as opposed to closing schools. We also note that we have more possible sub types for documenting health resources in the survey  (21 sub types) than restrictions of non-essential businesses (7 sub types). In the next subsection, we provide a more rigorous method of comparing policies while taking their depth into account. 

Additionally, our dataset also shows that the majority of countries in the world are a target of an external border restriction, quarantine measure, or health monitoring measure from another country. Moreover, a high percentage of policies documented in our dataset have mandatory enforcement.



<!--```{r desctab, results = 'hide'}

<!-- clean_data %>%  -->
<!--   group_by(type, country) %>%  -->
<!--   dplyr:::summarize(numPolicies=n(), -->
<!--                     numCountries=length(unique(country)), -->
<!--                     target_country = ifelse(any(grepl('All countries', target_country)), -->
<!--                                             205, 1+ length(unique(unlist(str_split(target_country[-which(is.na(target_country))], ','))))), -->
<!--                     percEnf =mean(grepl(x=compliance,pattern="Mandatory")*100,na.rm=T)) %>% -->
<!--   ungroup() %>% -->
<!--   mutate( type=recode(type, -->
<!--                       `Other Policy Not Listed Above`="Other", -->
<!--                       `Quarantine` = "Quarantine/Lockdown", -->
<!--                       `Closure and Regulation of Schools` = "Closure of Schools", -->
<!--                       `Restriction and Regulation of Businesses` = "Restriction of Non-Essential Businesses", -->
<!--                       `Restriction and Regulation of Government Services` = "Restriction of Non-Essential Government Services" -->

<!--                       #`New Task Force, Bureau or Administrative Configuration`="New Task Force" -->
<!--                       ))%>% -->
<!--   select(Type="type",everything()) %>%  -->
<!--   group_by(Type) %>% -->
<!--   dplyr:::summarize(`Total Number of Policies` = sum(numPolicies), -->
<!--                     `Number of Countries` =  sum(numCountries), -->
<!--     `Average Number of Targeted Countries`= round(mean(target_country)), -->
<!--     `% With Mandatory Enforcement` = round(mean(percEnf))) %>% -->
<!--   arrange(desc(`Total Number of Policies`))  %>%  -->
<!--   ungroup() #%>% -->
<!--   knitr::kable("latex",booktabs=T, -->
<!--                caption="Descriptive Information about the CoronaNet Government Response Dataset") %>% -->
<!--   kable_styling(latex_options = c("striped", "HOLD_position")) %>% -->
<!--   column_spec(1,width="4cm") %>% -->
<!--   column_spec(2:5,width="2.5cm") -->

<!-- ``` -->

In addition, in Figure 1, we investigate the cumulative incidence of different types of policies in our data over time. The figure shows that arguably relatively easy to implement policies like external border restrictions, the forming of task forces, public awareness campaigns, and efforts to increase health resources came relatively early in the course of the pandemic. Relatively more difficult policies to implement like curfews, closures of schools, restrictions of non-essential businesses and restrictions of mass gatherings arrived later.

```{r overtime,fig.cap="Cumulative Incidence of Policy Event Types Over Time", fig.show='hide'}
 
clean_data %>% 
  filter(!is.na(type)) %>% 
         mutate( type=recode(type,
                     `Public Awareness Campaigns`="Public\nAwareness\nCampaigns",
                     `External Border Restrictions`="External\nBorder\nRestrictions",
                     `Other Policy Not Listed Above`="Other",
                     `Restriction of Non-Essential Businesses`="Restriction of\nNon-Essential\nBusinesses",
                     `Restriction and Regulation of Businesses` = "Restriction of\nNon-Essential\nBusinesses",
                     `Closure and Regulation of Schools` = "Closure of Schools",
                      `Restriction and Regulation of Government Services` = "Restriction of\nNon-Essential\nGovernment Services",
                     `Restrictions of Mass Gatherings`="Restrictions of\nMass Gatherings",
                       `Quarantine` = "Quarantine/Lockdown",
                     `Restriction of Non-Essential Government Services`="Restriction of\nNon-Essential\nGovernment Services",
                     `Declaration of Emergency`="Declaration of\nEmergency",
                     `Internal Border Restrictions`="Internal\nBorder Restrictions",
                     `External Border Restrictions`="External\nBorder Restrictions",
                     `Public Awareness Measures`="Public\nAwareness Measures",
                     `New Task Force, Bureau or Administrative Configuration`="New Task\nForce, Bureau or\nAdministrative \nConfiguration`")) %>% 
  group_by(type,date_announced) %>% 
  summarize(Policies=length(unique(record_id))) %>% 
  arrange(type,date_announced) %>% 
  mutate(Policies=cumsum(Policies)) %>% 
  ungroup() %>% 
 
  ggplot(aes(y=Policies,x=date_announced)) +
  geom_area() +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank()) +
  xlab("") +
  facet_wrap(~type)
ggsave("Figure1.jpg",height=200,width=180,units="mm", dpi = 300)

 
                    
                      


```


We can also explore the extent to which other countries are affected by policies that can have a geographic target outside the policy initiator (e.g. ‘external border restrictions’, ‘quarantine’) across time. For example, in Figure 2, we map a network of bans on inbound flights initiated by four European countries as of March 15, 2020: Italy, Greece, Albania and Romania . In the plot, each horizontal line represents a particular country (what in network terminology is called a node). The vertical lines denote whether there was such a flight ban between two countries (what in network terminology is called an edge or a link), and the arrow of the vertical line indicates the direction in which the ban is applied (what in network terminology allows us to capture directed dyads). For instance, the purple horizontal line represents Greece, and the vertical line connecting Greece to Italy shows that there was a flight ban between these two countries. The arrow pointing upwards to Italy shows that it was Greece which directed the flight ban against Italy. See Longabaugh for more information on how to interpret this plot (2012)[@longabaugh2012].

Extended Data Figure 1 depicts travel bans initiated by all European countries as of March 15, 2020. It shows that the governments of Poland and San Marino had banned all flights into Poland and San Marino respectively while the government of Italy banned incoming flights from China, Hong Kong, Macau and Taiwan. Additionally, the governments of Greece and Romania both banned flights from Italy while the government of Albania banned incoming flights from Greece. According to our data, up until this point in time, no other European governments at the national level had banned inbound flights from other countries. The availability of such dyadic data in this dataset may improve inference for any number of analyses which seek to investigate how actions undertaken by different governmental units are linked, including for example on how policies in one country affect health outcomes in another country. 

```{r biofe,fig.cap="Network Map of Bans on Inbound Flights by European Countries as of March 15, 2020", fig.show='hide'}

knitr::include_graphics("Figure2.jpg")

```


```{r, results='hide'}

# add region variable
clean_data$region = regions_df$regions[match(clean_data$country, regions_df$country)]

# create numeric ids per country; needed to create igraph
country_id = factor(unique(countries$Country))
levels(country_id ) = 1:length(country_id )
country_id = as.numeric(as.character(country_id))
cid = data.frame(country_name = countries$Country, country_id)
clean_data$country_id = cid$country_id[match(clean_data$country, cid$country_name)]
clean_data$target_country_id = cid$country_id[match(clean_data$target_country, cid$country_name)]

# user function for plotting biofabric plots by region, policy type, date, travel mechanism and travel direction

plotBioGraph = function(regionName,
                        countryName = NULL,
                        policyType,
                        dateStart,
                        allDum  = FALSE,
                        countryDum = FALSE,
                        travelMech = c('Flights' ,'All kinds of transport'),
                        travelDir = c("Inbound", "Inbound/Outbound"),
                        returnGraph = TRUE){
  
  # subset data
  sub_data = clean_data %>% filter(date_start<= dateStart)
  sub_data =  sub_data %>% filter(type == policyType )
  sub_data = sub_data %>% separate_rows(travel_mechanism, sep = ',')
  sub_data = sub_data %>% filter(travel_mechanism %in% travelMech)
  sub_data = sub_data %>% filter(target_direction %in% travelDir )
  
  # mandatory compliance
  sub_data = sub_data %>% separate_rows(compliance, sep = ',' )
  sub_data = sub_data %>% filter(compliance %!in% "Voluntary/Recommended but No Penalties")
  sub_data = sub_data %>% filter(target_country!="Other (please specify below)")
  
  
  # conditional logic for only selecting inbound flight bans external border restrctions
  if(policyType == 'External Border Restrictions'){
    sub_data = sub_data %>% filter(type_sub_cat %!in% c("Health Screenings (e.g. temperature checks)", "Health Certificates", "Travel History Form (e.g. documents where traveler has recently been)") )
    sub_data = sub_data %>% filter(target_who_what %in% c("All (Travelers + Residents)", "All Travelers (Citizen Travelers + Foreign Travelers )") )
  }
  
  ## Note, the following entry is not 'wrong', but is not a sweeping travel ban
  # Macau, not travel ban but health declaration doesn't fit into existing categories
  sub_data = sub_data %>% filter(policy_id %!in% c(4638284 ))
  
  # Italian ban only for Sardenia
  sub_data = sub_data %>% filter(policy_id %!in% c(4539256))
  
  # Portugal ban only for Maideria
  sub_data = sub_data %>% filter(policy_id %!in% c(6369772))
  ## FIX THE BELOW LATER IN QUALTRICS
  
  # this is not a travel ban for people entering Italy,but a health declaration form
  sub_data = sub_data %>% filter(policy_id %!in% c(1727181))
  
  # South Sudan, not a ban on all countries, but on unsepcified countries affected by covid
  sub_data = sub_data %>% filter(policy_id %!in% c(5302981))
  
  # add data for italy's ban of inbound flights from Taiwan, Hong Kong and Macau
  # currently not in the data but we should add these entries
  # https://www.reuters.com/article/china-health-taiwan-italy/italy-says-taiwan-flight-resumption-request-noted-after-virus-ban-idUSL4N2A52YR
  
  sub_data = sub_data %>% add_row(country = 'Italy', target_country = 'Taiwan', type = 'External Border Restrictions', target_direction = 'Inbound', travel_mechanism = "Flights", date_start = as.Date("2020-02-02"), region = 'Europe')
  sub_data = sub_data %>% add_row(country = 'Italy', target_country = 'Hong Kong', type = 'External Border Restrictions', target_direction = 'Inbound', travel_mechanism = "Flights", date_start = as.Date("2020-02-02"), region = 'Europe')
  sub_data = sub_data %>% add_row(country = 'Italy', target_country = 'Macau', type = 'External Border Restrictions', target_direction = 'Inbound', travel_mechanism = "Flights", date_start = as.Date("2020-02-02"), region = 'Europe')
  
  # add data for greece's ban of inbound/outbound flights from Italy
  # https://www.reuters.com/article/us-health-coronavirus-greece-death/greece-reports-two-more-coronavirus-fatalities-suspends-all-flights-to-italy-idUSKBN2110H1
  sub_data = sub_data %>% add_row(country = 'Greece', target_country = 'Italy', type = 'External Border Restrictions', target_direction = 'Inbound', travel_mechanism = "Flights", date_start = as.Date("2020-03-14"), region = 'Europe')
  
  
  # expand dataset to include disaggregated country data when applicable
  sub_data[which(sub_data$target_country == 'All countries'), 'target_country'] = paste(cid$country_name, collapse = ',')
  sub_data = sub_data %>% separate_rows(target_country, sep = ',')
  
  # remove duplicates
  sub_data = sub_data %>%
    distinct(country, target_country, .keep_all = TRUE)
  
  # subset to a region, if applicable
  if(allDum == FALSE){
    sub_data = sub_data %>% filter(region %in% regionName)}
  
  if(countryDum == TRUE){
    sub_data = sub_data %>% filter(country %in% countryName)}
  
  
  sub_data = sub_data %>% rename(from = country, to = target_country) %>% select(from, to)
  
  
  graph <- as_tbl_graph(sub_data)%>%
    mutate(group =  factor( rep(1:7, length.out = length(name))   )) %>%
    activate(edges) %>%
    mutate(edge_group = factor( rep(1:7, length.out = length(to))  ))# %>%
  
}
 

```



```{r biofe2,fig.cap="Network Map of Bans on Inbound Flights by Select European Countries as of March 15, 2020", fig.show='hide'} 
 
graph = plotBioGraph(regionName = "Europe", 
             countryName = c('Italy', 'Greece', 'Albania', 'Romania'),
             countryDum = TRUE,
             policyType = "External Border Restrictions",
             dateStart = "2020-03-15",
             returnGraph = FALSE)


ggraph(graph, 'fabric', sort.by = node_rank_fabric()) + 
  geom_node_range(aes(colour = group), alpha = 0.3, size = 1) + 
  geom_edge_span(aes(colour = edge_group), end_shape = 22, arrow = arrow(angle = 30, length = unit(.7, "cm"),
                                                 ends = "last", type = "closed"), edge_width = 1, lineheight = 100) + 
  geom_node_text(aes(label = c(name[1], NA,name[3], NA, name[5:8])), size = 6, nudge_x =-2.2)+

  coord_fixed() + 
  theme(legend.position = 'none')+
  scale_colour_manual(values = pal_npg("nrc", alpha = 0.9)(7))+
  scale_edge_colour_manual(values=pal_npg("nrc", alpha = 0.9)(7))+
  
  annotate("text", x=-1.3, y=7, label= "Italy", size = 6)+
  annotate("text", x=-.6, y=6, label= "Greece", size = 6)+
  annotate("text", x=3, y=7.75, label= "Italy", size = 8)+
  annotate("text", x=7, y=7.9, label= "Greece", size = 8, angle = 90)+
  theme(panel.background = element_blank())+
  expand_limits(x = c(-2, 5), y = c(0,9))
ggsave("Figure2.jpg", height = 115, width = 88, units = 'mm', dpi= 300)
``` 






## Government Policy Activity Index {-}

In this section, we briefly present our index for tracking the relative government activity with regards to policies targeting COVID-19 across countries and over time. The model is a version of item-response theory known as ideal point modeling which incorporates over-time trends [@kubinec2019ideal;@jackman2004;@gelman2005;@quinn2002;@barbera2015;@bonica2014], permitting inference on how a latent construct, in this case total policy activity, responds to changes in the pandemic. To fit the model, the different policy types shown in Table 1, as well as sub-policies within them, were coded in terms of ordinal values, with lower values for sub-national targets of policies and higher values for policies applying to the entire country, or in the case of external border restrictions, to one or more external countries. For instance, internal country policies can take on three possible values: no policy, sub-national policy, or policy covering the whole country. Meanwhile external border restrictions can take on four possible values: no policy, policy targeting one other country, policy targeting multiple countries, and policy targeting all countries in the world (i.e., border closure).  

We employed ideal point modeling because it can be given a latent utility interpretation [@jackman2004]. We assume that each country has an unobserved "ideal point" on a uni-dimensional space representing its willingness to impose policies, while each policy likewise has a position on the same space. The relative cost of different policies can be thought of as the distance between a country's ideal point and the ideal point of the policy relative to other policies. While the meaning of this implied cost will vary from country to country, it is likely a combination of the social, political and economic costs of implementing the policy at a given time point.

As countries become more willing to pay the implied cost (i.e. the latent distance between country and policy decreases), the country's ideal points/policy activity score will rise and they will implement more policies. This interpretation is similar to the traditional item-response theory approach for analyzing test questions in which students who correctly answer more questions on a test are considered to have higher "ability" [@takane1986; @reckase2009]. Following this logic, we are able to estimate latent country scores that represent the readiness of a country to impose a set number of policies. The implied cost of policies is estimated via discrimination parameters, which indicate how strongly policies discriminate between countries. 

The country-level policy activity score is further allowed to vary over time in a random-walk process with a country-specific variance parameter to incorporate heteroskedasticity [@quinn2002]. Incorporating over-time trends explicitly is very important for capturing the nuances of policy implementation over time. For example, countries that impose more restrictive policies at an earlier date will be rewarded with higher policy activity scores compared to those who impose such policies at a later date. Imposing a given policy when most countries have already imposed them will result in little if any change in the policy activity score. 

The advantage of employing a statistical model, rather than simply summing across policies, is that the index ends up as a weighted average, where the weights are derived from the probability that a certain policy is implemented. In other words, while many countries set up task forces, relatively few imposed curfews at an early stage. As a result, the model adjusts for these distinctions, producing a score that aggregates across the patterns in the data. 

Furthermore, because the model is stochastic, it is robust to some of the coding errors of the kind that often occur in these types of datasets. As we discuss in our validation section, while we are continuing to validate the data on a daily basis, the massive speed and scope of data collection means that we cannot identify all issues with the data in real time. However, the measurement model employed only requires us to assume that on average the policy codings are correct, not that they are correct for each instance. Coding error, such as incorrectly selecting a policy type, will propagate through the model as higher uncertainty intervals, but will not affect average posterior estimates. As our data quality improves, and we are able to collect more data over time, the model will produce more variegated estimates with smaller uncertainty intervals.

Figure 3 shows the estimated index scores for the `r length(unique(clean_data$country))` countries in our dataset at present, and suggests strong evidence of policy diffusion effects. While information about COVID-19 existed at least as early as January, we do not see large-scale changes occurring in activity scores until March. Furthermore, the trajectories are highly non-linear, with a large number of countries quickly transitioning from relatively low to relatively high scores. This non-linear movement could be due to a variety of factors, including the rapid spread of the virus and policy learning as states observe other states' policy actions. We note that the country that appeared to take the quickest action in the shortest amount of time is New Zealand, as can be seen in Figure 5 where we show over-time variance parameters for each country. For an interactive version of this figure, please see our website.

Of course, a caveat with the index is that we may be missing some possible policy measures that have occurred due to the difficulty in finding them in published sources. However, there is still clear differentiation within the index in terms of when policies were imposed, with some countries starting to impose policies much earlier than others. Furthermore, there is a clear break around March 1st when countries began to impose more stringent policies across the world.


```{r plotindex,fig.cap="CoronaNet Time-Varying Index of National Policy Activity of Measures Opposing COVID-19 Pandemic. ", fig.show='hide'}

# severity_fit <- readRDS("../data/activity_fit_rw.rds")
# 
# all_lev <- as.character(unique(clean_data$init_country))
# 
# get_est <- as.data.frame(severity_fit@stan_samples,"L_tp1") %>%
#   mutate(iter=1:n()) %>%
#   gather(key="parameter",value="estimate",-iter) %>%
#   mutate(date_announced=as.numeric(str_extract(parameter,"(?<=\\[)[1-9][0-9]?[0-9]?0?")),
#          country=as.numeric(str_extract(parameter,"[1-9][0-9]?[0-9]?0?(?=\\])")),
#          country=factor(country,labels=levels(severity_fit@score_data@score_matrix$person_id)),
#          date_announced=factor(date_announced,labels=as.character(sort(unique(severity_fit@score_data@score_matrix$time_id)))))
# 
# saveRDS(get_est,"../data/get_est.rds")

get_est <- readRDS("../../data/get_est.rds")
 
 
get_est_sum <- get_est %>%
            ungroup %>%
  filter(country!="Chad") %>%
            mutate(estimate=plogis(estimate)*100,
                   date_announced=ymd(as.character(date_announced))) %>%
  group_by(country,date_announced) %>%
  summarize(med_est=median(estimate),
            high_est=quantile(estimate,.95),
            low_est=quantile(estimate,.05)) %>%
  group_by(date_announced) %>%
  mutate(`Country Rank`=rank(med_est))
 

list_countries <- c("United States of America",
                   # "United Kingdom",
                    "China",
                    "Taiwan",
                    "Germany",
                    "Singapore",
                    "Italy",
                    "France",
                    "South Korea",
                    "Gabon",
                   # "Croatia",
                    "United Arab Emirates",
                    "Yemen"#,
                   # "St. Lucia"
                    )

random_country <- group_by(get_est_sum,country) %>% 
  sample_n(1)

# need a way to facet this

# facets <- lapply(c("Jan","Feb","Mar","Apr"), function(m) {
#   mutate(get_est_sum,month_facet=m)
# }) %>% bind_rows

to_plot <- get_est_sum %>%
  ungroup %>%
  mutate(month_var=month(date_announced,label=T)) %>% 
  group_by(month_var,country) %>% 
  mutate(country_spread=unique(med_est[date_announced==max(date_announced)]) - unique(med_est[date_announced==min(date_announced)])) %>% 
  ungroup

calc_ranks <- select(to_plot,country_spread,country,month_var) %>% distinct %>% 
  arrange(month_var,desc(country_spread)) %>% 
  group_by(month_var) %>% mutate(count_rank=rev(rank(country_spread)))
    
  
  
  breakout <- to_plot  %>%
    left_join(calc_ranks,by=c("country","country_spread","month_var")) %>% 
  filter(month_var!="Dec") %>% 
  ungroup %>% 
  ggplot(aes(y=med_est,x=date_announced)) +
  #geom_ribbon(aes(ymin=low_est,ymax=high_est,group=country),alpha=0.2) +
  geom_line(aes(group=country,colour=med_est),alpha=0.2, size = 1) +
  scale_color_distiller(palette="Blues",direction=1) +
  gghighlight(count_rank<4,
              calculate_per_facet = T,
              label_params=list(size=2.5,colour="black",direction="both",
                                force=1.7,
                                label.padding=0.1,
                                segment.curvature=-.5),
              unhighlighted_params = list(size = .5, colour = alpha("grey", 0.3))) +
  # scale_color_manual(name="Country",values=c('#00CC33','#E69F00','#CC0000',"#FF99FF","#99CCFF","#006699","#990099","orangered1","#9933FF","yellow3", "blue1" ))+
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text.x=element_text(angle=45)) +
  xlab("") +
  ylab("") +
  facet_wrap(~month_var,scales = "free_x")
  
overall <- to_plot  %>%
  group_by(date_announced) %>% 
  mutate(all_rank=rev(rank(med_est))) %>% 
  ungroup %>% 
    mutate(last_rank = ifelse(date_announced==max(date_announced),`Country Rank`,NA),
         lab_country = ifelse(last_rank %in% c(4,14,68,92,125,181,191),as.character(country),
                              NA)) %>% 
  ungroup %>% 
  ggplot(aes(y=med_est,x=date_announced)) +
  #geom_ribbon(aes(ymin=low_est,ymax=high_est,group=country),alpha=0.2) +
  #geom_line(aes(group=country,colour=med_est),alpha=0.7, size = 1) +
  #scale_color_distiller(palette="Blues",direction=1) +
  geom_line(aes(group=country), color="lightgrey", size=0.1) +
  geom_line(data=to_plot[to_plot$country%in% c("Spain","Italy","United Kingdom","United States of America","Comoros","Yemen"),],aes(group=country,colour=med_est),alpha=0.7, size = 1) +
     scale_color_distiller(palette="Blues",direction=1) +
  geom_label_repel(aes(label=lab_country),size=2.5) +
  # scale_color_manual(name="Country",values=c('#00CC33','#E69F00','#CC0000',"#FF99FF","#99CCFF","#006699","#990099","orangered1","#9933FF","yellow3", "blue1" ))+
  theme_minimal() +
  theme(panel.grid = element_blank()) +
  # labs(caption="Estimates are derived from Stan, a Markov Chain Monte Carlo sampler.\nThe intervals represent the median and 5% - 95% posterior density region.\nPlot shows one estimate per country per day.") +
  xlab("") +
  ylab("Policy Activity Index Scale (0 to 100)") +
  guides(color="none")

overall + breakout +
  plot_annotation(tag_levels="A")

ggsave("Figure3.jpg", width = 180, height = 170, units = 'mm', dpi = 300)




```


Table 2 shows the discrimination parameters from the underlying Bayesian model for each policy type. These parameters suggest which policies governments find relatively difficult or costly to implement, and for that reason tend to separate more active from less active states in terms of response to COVID-19. Two of these policies (Closure of Restaurants and Quarantine at Home) were given fixed values in order to identify the direction and rotation of the latent scale, and so their discrimination parameters are not informative. These policies were chosen as *a priori* we can identify them as being relatively high cost. However, the rest of the parameters were allowed to float, which provides inference as to which policies appear to be the most difficult/costly to implement.

We note that these are average values for the sample. Imposing these policies may be less costly for certain countries or for countries that share certain characteristics, such as having smaller numbers of enrolled students or relatively healthy economies. However, it is important to note that we can see these patterns on a world-wide scale.


At the top of the index we see various business closure policies as the most difficult to implement, while school closures are the next most difficult. Closure of pre-schools, though, as opposed to other school types, appears to be relatively less costly for states to undertake, perhaps because pre-schools do not operate on a full-time basis. Internal border restrictions are considered more difficult to implement than external border restrictions, while relatively straightforward policies like public awareness campaigns, health monitoring and opening new task forces or bureaus are near the bottom of the index. Quarantines placing people in external facilities, such as hotels or government quarantine centers, are also estimated as being less costly than quarantine at home (stay-at-home orders).

Given this distribution of discrimination parameters, we believe the index is a valid representation of the underlying process by which governments progressively impose more difficult policies. As states relax policies, we will further gain information about which policies appear to be more costly as we will be able to factor in the duration for which these policies were implemented. Consistent with our findings, we observe that the announced relaxation policies happening at the time of writing in European countries primarily center on businesses and school openings, suggesting that these policies are uniquely costly to keep in place compared to travel restrictions [@doherty2020].



```{r rankcount, results='hide'}

# out_items <- summary(severity_fit,pars="items") %>%
#   filter(`Item Type`=="Non-Inflated Discrimination")
# 
# saveRDS(out_items,'../data/out_items.rds')

out_items <- readRDS("../../data/out_items.rds")

out_items %>% 
  mutate(`Item Name`=recode(`Item Name`, `Closure of Schools`="All Schools",
                `Closure of Schools_type_highered`="Higher Ed Closure",
                `Closure of Schools_type_preschool`="Pre-school Closure",
                `Closure of Schools_type_primaryschool`="Primary School Closure",
                `Closure of Schools_type_secondschool`="High School Closure",
                `Curfew_`="Curfew",
                `Declaration of Emergency_`="Declaration of Emergency",
                `External Border Restrictions_`="External Border Closure",
                `External Border Restrictions_Other External Border Restriction`="Other Border Restriction",
                `External Border Restrictions_health_cert`="Border Health Certificates",
                `External Border Restrictions_travel_hist`="Travel History Required",
                `External Border Restrictions_Visa restrictions (e.g. suspend issuance of visa)`="Suspend Visa Issuance",
                `Health Monitoring_`="Monitoring Population Health",
                `Health Resources_`="Other Health Resources",
                `Health Resources_Doctors`="Mobilization of Doctors",
                `Health Resources_health_research`="Biomedical Research",
                `Health Resources_Hospitals`="Supporting Hospitals",
                `Health Resources_Nurses`="Mobilization of Nurses",
                `Health Resources_other_facilities`="Other Health Facilities",
                `Health Resources_Personal Protective Equipment`="PPE Mobilization",
                `Health Resources_public_tests`="Public Testing Mobilization",
                `Health Resources_quar_facility`="Building Quarantine Facilities",
                `Health Resources_Unspecified Health Infrastructure`="Other Health Facilities",
                `Health Resources_ventilators`="Mobilization of Ventilators",
                `Health Resources_volunteers`="Mobilization of Volunteers",
                `External Border Restrictions_type_screenings`="Border Health Screenings",
                `Health Resources`="General Health Resources",
                `Health Testing_`="Mobilization of Testing",
                `Internal Border Restrictions_`="Internal Border Restrictions",
                `Public Awareness Measures_`="Public Awareness Measures",
                `New Task Force, Bureau or Administrative Configuration_`="Task Force",
                `Quarantine/Lockdown_`="Quarantine/Lockdown",
                `Quarantine/Lockdown_hotel_quar`="Quarantine in Hotel",
                `Quarantine/Lockdown_Other Quarantine`="Other Quarantine",
                `Restriction of Non-Essential Businesses_`="Restriction Other Business",
                `Restriction of Non-Essential Businesses_type_commerce`="Restriction Commercial Business",
                `Restriction of Non-Essential Government Services_`="Restriction Government Services",
                `Restrictions of Mass Gatherings_`="Restriction of Mass Gatherings",
                `Social Distancing_`="Social Distancing",
                `Health Resources_type_health_masks`="Masks Policies",
                `Health Resources_type_health_other`="Other Health Resources",
                `Health Resources_type_health_staff`="Other Health Staff",
                `Health Resources_type_sanitizer`="Sanitizer Policies",
                `Health Resources_type_temporary`="Temporary Medical Units",
                `Health Resources_type_testing`="Test Production",
                `Quarantine/Lockdown`="Other Quarantines",
                `Quarantine/Lockdown_type_govt_quar`="Quarantine in Govt. Facility",
                `Quarantine/Lockdown_type_quar_restrict`="Limited Quarantine",
                `Quarantine/Lockdown_type_screenings`="Quarantine Screenings",
                `Quarantine/Lockdown_type_self_quarantine`="Quarantine At Home",
                `Restriction of Non-Essential Businesses`="General Business Restrictions",
                `Restriction of Non-Essential Businesses_type_bars`="Closure of Restaurants",
                `Restriction of Non-Essential Businesses_type_grooming`="Closure of Personal Grooming",
                `Restriction of Non-Essential Businesses_type_retail`="Closure of Retail Stores",
                `Restriction of Non-Essential Businesses_type_shopping`="Closure of Shopping Malls")) %>% 
  select(Policy="Item Name",`5% Low Estimate`="Low Posterior Interval",
         `Median Estimate`="Posterior Median",
         `95% High Estimate`="High Posterior Interval") %>%
  mutate(`Median Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `Median Estimate`*-1,
                                  `Median Estimate`),
         `5% Low Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `5% Low Estimate`*-1,
                                  `5% Low Estimate`),
         `95% High Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `95% High Estimate`*-1,
                                  `95% High Estimate`)) %>% 
  arrange(desc(`Median Estimate`)) %>%
  mutate_at(c("5% Low Estimate","Median Estimate","95% High Estimate"),~round(.,1)) %>%
    knitr::kable("latex",booktabs=T,longtable=T,
               caption="Discrimination of Item Parameters (Policies) in Policy Activity Index") %>%
  kable_styling(latex_options = c("striped", "hold_position"),font_size = 9) %>%
  column_spec(1,width="4cm") %>%
  column_spec(2:5,width="2.5cm")
```


# Discussion {-}

As policymakers, researchers and the broader public debate and compare how to succeed against the novel threats posed by COVID-19, they need real-time, traceable data of government policies in order to understand which of these policies are effective, and under what conditions. This requires specific knowledge of the variation of such policies and how widely implemented they are across countries and time. The goal of the dataset and policy action index presented here is to provide this information.

We have tried to match our data collection efforts to keep up with the exponential speed with which COVID-19 has already upended global public health and the international economy while also maintaining high levels of quality. However, we will inevitably be refining, revising and updating our data to reflect new knowledge and trends as the pandemic unfolds. The data that we present here represents an initial release; we will continue to validate and release data so long as governments continue to develop policies in response to COVID-19.

In future work, we intend to analyze the policy combinations that are best able to stymie the pandemic so as to contribute to the research community and provide urgently needed knowledge for policymakers and the wider global public.

# Methods {-}

In this section, we first describe the variables that our dataset provides as well as how they are organized. We then provide detail on the methodology we employed to collect the data. Following this, we provide more detail on the methodology we employed to estimate our government policy action index.


## Data Schema {-}

Each unique record documents at the minimum, the following information: the policy type; the name of the country from which a policy originates (if the policy originates from a province or state, that information is also documented. Future versions of the dataset will also include information on whether a policy was initiated from a city or municipality or another level of government); the degree to which a policy must be complied with; the entity enforcing the policy; the date a policy is announced, implemented and ends. Note that sometimes policies are announced without a pre-determined end date. In those cases, this field is left blank.

For all policies, the database further documents information about the geographic target of the policy and the human or material target of a policy. Note however, for some policies, the geographic target may be the same as the policy initiator and in those cases can be considered monadic. Where applicable, we also document the directional flow of the policy, and what mechanism of travel (e.g. flights, trains) a policy is targets. 

All of the information mentioned above is also provided qualitatively via a textual event description. Additional meta-data that is available for all policies include when the record entered into the database and a link for the information source for the policy. See Supplementary Methods Appendix A for a list of currently available fields in the data, along with a list of external data variables such as country-level covariates that are added to daily releases, including COVID-19 tests and cases. 

There is a unique record ID for each unique policy announcement per initiating country, which we code at the policy sub type. That is, some policy types are further categorized into sub types. For example, ‘Quarantine’ can be further classified into one or more of the following sub types: ‘Self-Quarantine’, ‘Government Quarantine’, ‘Quarantine outside the home or government facility’, ‘Quarantine only applies to people of certain ages’ and ‘Other’. Of the `r length(unique(clean_data$record_id))` such events in the dataset, we have identified `r length(unique(clean_data$record_id[clean_data$entry_type %in% c("correction","new_entry")]))` unique events. That is, some events in the database are updates or changes to existing policies. We link such events over time using a unique ID, which we term the policy ID as opposed to the record ID. An event counts as an update if it deals with a change in either the:

1.	The time duration (e.g. A country lengthens its quarantine to 28 days from 14 days.)
2.	The quantitative ‘amount’ of the policy (e.g. A restriction of mass gatherings was previously set at 100 people and now it is set at 50 people).
3.	A set of other policy dimensions:
   a.	Who the policy applies towards (e.g. The quarantine used to apply to people of all ages and now it only applies to the elderly).
   b.	The directionality of the policy (e.g. a travel ban previously banned inbound flights from country X and now bans both inbound and outbound flights to and from country X).
   c.	The travel mechanism (e.g. a travel ban was previously applied towards all types of travel but now only applies towards flights).
   d.	The compliance rules for the policy (e.g. The quarantine used to be voluntary but is now mandatory).
   e.	The enforcer of a policy (e.g. the policy was previously under the purview of the ministry of health but was changed to the ministry of the interior).  


A policy counts as a new entry and not an update if it deals with a change in any other dimension, e.g. the qualitative policy type (e.g. a quarantine used to mandate a stay in a government facility but now quarantine at home is allowed) or the targeted country (e.g. quarantine upon arrival was mandated for people traveling from China but now these rules also apply to people traveling from Italy). In those cases, or when a policy is completely cancelled or annulled, the policy is coded as having ended. 

## Data Collection Methodology {-}
As researchers learn more about the various health, economic, and social effects of the COVID-19 pandemic, it is crucial that to the greatest extent possible, they have access to data that is reliable, valid, and timely. We have adopted a data collection methodology that we believe optimizes over all three of these constraints.

To collect the data, we recruited more than 260 research assistants (RAs) from colleges and universities around the world, representing 18 out of the 24 time zones.  Large social scientific datasets typically rely on experts, coders, or crowd-sourcing to input data. The literature has shown that common coding tasks can be completed via crowd-sourcing [@benoitetal2016; @sumneretal2019], but that there are also limitations to the wisdom of crowds when specific contextual or subject knowledge is required [@marquardtetal2017; @Urlacher2017]. To address these trade offs, we decided to train current RAs to code our entries, leveraging the benefits of wide-spread recruitment and a diverse pool of country-specific knowledge from across the globe. Data collection started on March 28, 2020 and has proceeded rapidly, reaching `r length(unique(clean_data$record_id))` records as of the date of this article. Each RA is responsible for tracking government policy actions for at least one country. RAs were allocated depending on their background, language skills and expressed interest in certain countries [@Horn2019]. Note depending on the level of policy coordination at the national level, certain countries were assigned multiple RAs, e.g. the United States, Germany, or France.

We have also partnered with the machine learning company Jataware to automate the collection of more than 200,000 news articles from around the world related to COVID-19. Jataware employs a natural language processing (NLP) classifier using Bidirectional Encoder Representations from Transformers (BERT) to detect whether a given article is indicative of a governmental policy intervention related to COVID-19. They then apply a secondary NLP classifier to categorize the type of policy intervention based on the definitions in our codebook (e.g. "declaration of emergency", "quarantine", etc.). Next, Jataware extracts the geospatial and temporal extent of the policy intervention (e.g. “Washington DC” and “March 15, 2020”) whenever possible. The resulting list of news sources is then provided to our RAs as an additional source for manual coding and further data validation.

In what follows, we describe in greater detail how RAs document the policies that they identify using our data collection software instrument, and our post data-collection validation procedure. Please refer to the Supplementary Methods Appendix B for more information on our procedure for on-boarding and training RAs and our system for communicating with and organizing RAs.


### Data Collection Software Instrument {-}

We designed a Qualtrics survey with survey questions to systematize and streamline the documentation of a given government policy over a wide range of dimensions. With this tool, RAs can easily and efficiently document information about different policy actions by answering the relevant questions posed in the survey (Büthe, Minhas and Lieu, unpublished manuscript). For example, instead of entering the country that initiated a policy action into a spreadsheet, RAs answer the following question in the survey: "From what country does this policy originate?" and choose from the available options given in the survey.

By using a survey instrument to collect data, we are able to systematize the collection of very fine-grained data while minimizing coding errors common to tools like shared spreadsheets. The value of this approach of course, depends on the comprehensiveness of the questions posed in the survey, especially in terms of the universe of policy actions that countries have implemented against COVID-19. For example, if the survey only allowed RAs to select 'quarantines' as a government policy, it would not capture any data on 'external border restrictions', which would seriously reduce the value of the resulting data. 

As such, to ensure the comprehensiveness of the data, before designing the survey, we collected in depth, over-time data on policy actions taken by one country since the beginning of the outbreak, Taiwan, as well as cross-national data on travel bans implemented by most countries for a total of 245 events. The specific data source we cross referenced for this effort was the March 20, 2020 version of a New York Times article on travel restrictions across the globe [@salcedo2020]. 

We chose to focus on Taiwan on because of its relative success, as of March 28, 2020, in limiting the negative health consequences of COVID-19 within its borders[@beech2020]. As such, it seemed likely at the time that other countries would choose to emulate some of the policy measures that Taiwan had implemented, bolstering the comprehensiveness of the questions we ask in our survey. Indeed at the time of writing, it would appear that some countries have indeed sought to mirror some parts of Taiwan's response[@aspinwall2020]. 

Meanwhile, by also investigating variation in how different countries around the world have implemented travel restrictions, we have also helped ensure that our survey is able to comprehensively document variation in how an important and commonly used policy tool is applied, e.g., restrictions on different methods of travel (e.g. flights, cruises), restrictions across borders and within borders, restrictions targeted toward people of different statuses (e.g. citizens, travelers).

<!-- As a last step, the team also consulted the ACAPS COVID-19: Government Measures Dataset^[https://data.humdata.org/dataset/acaps-covid19-government-measures-dataset] to validate the comprehensiveness of the policy measures considered in the survey instrument.  -->

<!-- To further address concerns about the comprehensiveness of our data, the survey instrument also allows for a degree of flexibility in learning about new policies that we might not have considered when designing the survey with the use of text entry fields that allows RAs to choose 'Other' categories that. To date, X% of the the data has been coded as 'Other' suggesting that [....]. Please see the descriptive statistics in the Data section for more information.  -->

There are many additional benefits of using a survey instrument for data collection, especially in terms of ensuring the reliability and validity of the resulting data:

1. Preventing unforced measurement error: RAs are prevented from entering data into incorrect fields or unknowingly overwriting existing data---as would be possible with manual data entry into a spreadsheet---because RAs can only document one policy action at a time in a given iteration of a survey and do not have access to the full spreadsheet when they are entering in the data. 

2. Standardizing responses: We are able to ensure that RAs can only choose among standardized responses to the survey questions, which increases the reliability of the data and also reduces the likelihood of measurement error. For example, when RAs choose different dates that we would like them to document (e.g., the date a policy was announced) they are forced to choose from a calendar embedded into the survey which systematizes the day, month and year format that the date is recorded in. 

3. Minimizing measurement error: A survey instrument allows coding different conditional logics for when certain survey questions are posed. This technique obviates the occurrence of logical fallacies in our data. For example, we are able to avoid situations where an RA might accidentally code the United States as having closed all schools in another country.

4. Reduction of missing data: We are able to reduce the amount of missing data in the dataset by using the forced response option in Qualtrics. Where there is truly missing data, there is a text entry at the end of the survey where RAs can describe what difficulties they encountered in collecting information for a particular policy event. 

5. Reliability of the responses: We increase the reliability of the documentation for each policy by embedding descriptions of different possible responses within the survey. For example, in the survey question where RAs are asked to identify the policy type (`type` variable, see Supplementary Methods Appendix A), the survey question includes pop-up buttons which allow RAs to easily access descriptions and examples of each possible policy type. Such pop-up buttons were also made available for the survey questions which code for the people or materials a policy was targeted at (`target_who_what`) and whether the policy was inbound, outbound or both (`target_direction`). Embedding such information in the dataset both clarifies the distinction between different answer choices and increases the efficiency of the policy documentation process (as RAs are not obliged to refer back and forth from the survey to the codebook). 

6. Linking observations. The use of a survey instrument facilitates the linking of policy events together over time should there be updates to existing policies. Once coded, each policy is given a unique Record ID, which RAs can easily look up, reference and link to if they need to update a particular policy.



### Post-Data Collection Validation Checks {-}

We further implement the following processes to validate the quality of the dataset:

1. Cleaning: Before validation, we use a team of RAs to check the raw data for logical inconsistencies and typographical errors. The data will also become part of a larger effort commissioned by the World Health Organization to collate different datasets on government actions taken in response to COVID-19. To that end, future versions of the data will be further cleaned with resources from this collaborative effort [@gibney2020].


2. Multiple Coding for Validation: Others have shown that the random allocation of tasks and the validation of labels by more than one coder are among the best ways to improve the quality of a dataset [@Sheng2008;@MTurk2011]. We randomly sample 10% of the dataset using the source of the data (e.g. newspaper article, government press release) as our unit of randomization. We use the source as our unit of randomization because one source may detail many different policy types. We then provide this source to a fully independent RA and ask her to code for the government policy contained in the sampled source in a separate, but identical, survey instrument. If the source is in a language the RA cannot read, then a new source is drawn. The RA then codes all policies in the given source. This practice is repeated a third time by a third independent coder. Given the fact that each source in the sample is coded three times, we can assess the reliability of our measures and report the reliability score of each coder.

3. Evaluation and Reconciliation: We then check for discrepancies between the originally coded data and the second and third coding of the data through two primary methods. First, we use majority-voting to establish a consensus for policy labels. Using the majority label as an estimate of the "hidden true label" is a common method to address classification problems [@Raykar2009]. One issue with this approach is that it assumes that all coders are equally competent [@Raykar2010]. This criticism is generally levied at data creation with crowd-sourced laborers. We mitigate this problem by training our RAs in the data collection process and prioritizing RA country-knowledge and language skills, therefore ensuring a more equal baseline for RA quality. In addition, we will provide RA identification codes that will allow users to evaluate coder accuracy.

If the majority achieves consensus, then we consider the entry valid. If a discrepancy exists, a fourth RA or PI makes an assessment of the three entries to determine whether one, some, a combination of all three is most accurate. Reconciled policies are then entered into the dataset as a correction for full transparency. If an RA was found to have made a coding mistake, then we sample six of their previous entries: 3 entries which correspond to the type of mistake made (e.g. if the RA incorrectly codes an 'External Border Restriction' as a 'Quarantine', we sample 3 entries where the RA has coded a policy as being about a 'Quarantine') and randomly sample 3 more entries to ascertain whether the mistake was systematic or not. If systematic errors are found, entries coded by that individual will be entirely recoded by a new RA.

At the time of writing, we are in the process of completing our second coding of the validation sample. Thus far, 297 policies have been double coded---276 double-coded policies after excluding the category 'Other policies' from the analysis---out of the original 500 randomly-selected policies included in our validation set. This is equivalent to 10\% of the first 5,000 policies in the dataset. We will be gradually expanding the validation set until we cover 10\% of all observations. 

We provide several measures in Table 3 to evaluate the inter-coder reliability at this early stage of validation. We find remarkable heterogeneity in the inter-coder reliability across types of policies. Our coders show a substantial level of agreement on policies such as 'Restrictions of Mass Gatherings' (n = 21, k = 0.95), 'Closure of Schools' (n = 14, k = 0.92), 'Restrictions of Non-Essential' (n = 19, k = 0.89), 'External Border Restrictions' (n = 52, k = 0.83), 'Curfew' (n = 6, k = 0.82), and Internal Border Restrictions (n = 11, k = 0.80). However, we also observe poor inter-rater agreement scores in other policies such as 'Social Distancing' (n = 14, k = 0.38), 'Public Awareness Measures' (n = 15, k = 0.49), and 'New Task Force, Bureau or Administrative Configuration' (n = 9, k = 0.52). Overall, these statistics indicate substantial levels of overall agreement between coders with inter-coder reliability scores between 0.71 and 0.74 (n = 276).

Our initial assessment of miscodings suggests that our coders have difficulties in distinguishing 'Social Distancing' policies from 'Quarantine/Lockdowns' and 'Public Awareness Campaigns'. We have taken some steps to ameliorate these issues. First, we have recently separated Quarantine from Lockdowns in our codebook and survey. Second, we have added branching logic into the Qualtrics survey that also clarifies the specific sub-policies that fall under 'Quarantine', 'Lockdowns', and 'Social Distancing'. Additionally, we have added several sub-types of 'Public Awareness Campaigns' in the survey that should provide conceptual clarity to this policy category. Further, the creation of a 'New Task Force, Bureau or Administrative Configuration' often goes together with a number of additional policies. In these cases, some of our coders seem to focus on these additional policies rather than on the creation of administrative units, which lowers the reliability of the coding system for this policy. We have provided RAs with better guidance on this category and have also added several sub-types for this question to help improve conceptual clarity for this policy category.  Finally, we have detected extremely poor reliability for the health-related policies of 'Health Monitoring' and 'Health Testing'. We have clarified the distinction across the three health-related policies---namely, 'Health Resources', 'Health Monitoring' and 'Health Testing'---in the codebook and we combine them under the category of 'Health Measures' in this on-going validation.

In the following weeks, we expect inter-coder reliability scores to improve as a consequence of three processes: (a) our coders are becoming more experience with the codebook and the coding tasks in general; (b) we are cleaning the dataset of obvious errors and logical inconsistencies; and, (c) we are working on clarifying and improving the codebook and the coding system. Notwithstanding these processes, we acknowledge that some ambiguities will unavoidably remain providing evidence for the utility of our planned "majority voting" validation strategy.


## Time-Varying Item Response Model {-}

Our time-varying item response model follows the specification in Kubinec (2019)[@kubinec2019]. We review that notation here to show how it relates to classical item-response theory as well as the ideal point modeling literature. 

The likelihood function for the model is as follows for a set of countries $i \in I$, items $j \in J$, time points $t \in T$ and ordinal categories $k \in K$:

\begin{align}
	L(Y_{ijtk}|\alpha_{it},\gamma_j,\beta_j) =  \prod_{i=1}^{I} \prod_{j=1}^{J} \prod_{t=1}^{T}
	\begin{cases} 
	1 -  \zeta(\gamma_j \alpha_{it} - \beta_j - c_1) & \text{if } K = 0 \\
	\zeta(\gamma_j \alpha_i - \beta_j - c_{k-1}) - \zeta(\gamma_j \alpha_{it} - \beta_j - c_{k})       & \text{if } 0 < k < K, \text{ and} \\
	\zeta(\gamma_j \alpha_{it} - \beta_j - c_{k-1}) - 0 & \text{if } k=K
	\end{cases}
(\#eq:basic)
\end{align}

In this equation, the time-varying country parameters $\alpha_{it}$, also called person abilities or ideal points, are our estimate of policy activity scores. They are estimated jointly with the item (policy type) discrimination parameters $\gamma_j$ and item difficulty (intercept) parameters $\beta_j$. To address the ordinal nature of the outcome $Y_{ijtk}$, ordinal cutpoints $c_{k}$ are used to model the varying levels of enforcement and geographical targets in the data. The logit function, represented by $\zeta(\cdot)$, maps the latent scale to probability that a given ordinal outcome is chosen. Because we have two separate type of ordered measures (domestic versus international policies) with either three or four ordered categories, we estimate the model jointly as two ordered logit specifications. 

The likelihood in \@ref(eq:basic) is not fully identified due to possible scaling issues with the latent variable $\alpha_{it}$ (i.e., it has no natural units) and due to potential sign reflection (also called multi-modality) where $L(Y_{ijtk})$ could be unchanged even if $\alpha_{it}$ is multiplied by -1. These identification issues are well-known in the literature [@gelman2005], and we resolve them with standard practices. First, we assign a reasonably informative prior distribution on the $t=1$ ideal points:

\begin{equation}
\alpha_{it=1} \sim N(0,1)
(\#eq:id1)
\end{equation}

We also fix the discrimination parameters $\gamma_j$ for two items, quarantines and restriction of restaurants and bars, to opposite ends of the latent scale (+1 and -1). Because both of these variables load on the same side of the scale (i.e. both indicate more policy activity), we reverse the order of the categories for restriction of restaurants and bars. We note that these types of restrictions are not commonly used in traditional IRT, where instead a sign restriction is imposed on all discrimination parameters. We employ the more flexible ideal point specification, which also allows us to test the assumption that all the discrimination parameters load on the same sign (as Table 2 shows, this is true for all of the parameters). The rest of the parameters are given weakly informative prior distributions (note a prior is put over the difference of cutpoints, rather than the cutpoints themselves, to reflect the fact that only the differences between cutpoints have any natural scale):

\begin{align}
\gamma_j &\sim N(0,5)\\
\beta_j &\sim N(0,2)\\
c_k - c_{k-1} &\sim N(0,5)
(\#eq:id2)
\end{align}

Finally, to model the policy scores $\alpha_{it}$ as a random walk, we assign a prior that is equal to the prior period policy score plus normally-distributed noise:

\begin{align}
\alpha_{it} &\sim N(\alpha_{it-1},\sigma_i)\\
\sigma_i &\sim E(1)
(\#eq:rwc)
\end{align}

The over-time dimension induces a new source of identifiability issues, which we resolve by fixing the variance $\sigma_i$ of one of the countries (the United States) to 0.1 so that the over-time variance is relative to this constant. This constraint has a similar identification effect to the informative prior on the first period policy activity scores in \@ref(eq:id1).


## Model Convergence {-}

For estimation, we sample from four Markov Chain Monte Carlo (MCMC) chains with over-dispersed starting values using Stan, a Hamiltonian Markov Chain Monte Carlo (HMC) sampler [@carpenter2017]. We run the sampler for 800 iterations, 400 of which are discarded as warm-up. While this number of iterations is far less than other MCMC samplers, HMC is far more efficient at exploring the posterior density and we are able to achieve convergence using this number of iterations. 

We assess convergence using split-$\hat{R}$ by fitting four independent chains with over-dispersed starting values. $\hat{R}$ values for all parameters (which totaled more than 40,000) were 1.01 or less (see plot A in Extended Data Figure 2). Plot B in Figure in Extended Data Figure 2 shows the distribution of effective number of samples for the parameters, which is a way of comparing the auto-correlation in MCMC draws to independent draws without auto-correlation, such as we might obtain from a Monte Carlo simulation. Again, the number of effective samples is quite high, often exceeding the total number of empirical draws. This occurred because Hamiltonian Monte Carlo can produce more informative samples than even a Monte Carlo simulation because it can generate negatively correlated draws that explore the posterior space much more quickly.  We also assess convergence using trace plots, one of which is shown below for the time-varying country policy activity scores for the United States. Strong mixing between chains can be observed in the plot. Finally, we report no divergent transitions or iterations where the sampler reached its maximum tree depth, which are both signs of poor mixing in the chains. For these reasons, we are confident than the sampler reached a stationary distribution and was able to adequately explore the high-density regions of the joint posterior.

```{r modelconv,fig.cap="Convergence Diagnostics for Random-Walk HMC Fit. Plot A shows the distribution of split-Rhat values for all 40,000 parameters in the model, revealing most parameters are close to 1, which indicates strong convergence. The effective number of samples for parameters in plot B is also very high, often exceeding the total number of posterior draws. Plots C and D show strong mixing across chains for the intercept and over-time parameter for the United States for January 30th.", fig.show='hide'}
# rhat <- id_plot_rhats(severity_fit) +
#   xlab(expression("split-"~hat(R)))
# 
# # let's get ESS
# 
# ess_sum <- summary(severity_fit@stan_samples)[[1]]
# 
# # filter out absence parameters (not used)
# 
# ess_sum <- ess_sum[!grepl("abs|A\\_int",row.names(ess_sum)),]
# 
# # plot as histogram
# 
# ess_plot <- as_tibble(ess_sum) %>%
#   gather(key="variable",value="value") %>%
#   filter(variable=="n_eff") %>%
#   ggplot(aes(x=value)) +
#   geom_histogram() +
#   theme(panel.grid = element_blank(),
#         panel.background = element_blank()) +
#   ylab("") +
#   xlab("Number of Effective\nSamples")
# 
# trace1 <-  stan_trace(severity_fit@stan_samples,"L_full[1]") +
#   ylab("U.S. Intercept") +
#   xlab("Posterior Iteration") +
#   theme(axis.text=element_text(size=8),
#         axis.title = element_text(size=8)) +
#   guides(color=guide_legend(title="Chain",title.position="top")) +
#   theme(legend.title = element_text(size=8))
# trace2 <- stan_trace(severity_fit@stan_samples,"L_tp1_var[1,30]") +
#   ylab("U.S. Jan. 30th") +
#     xlab("Posterior Iteration") +
#   theme(axis.text=element_text(size=8),
#         axis.title = element_text(size=8)) +
#   guides(color='none')
# rhat + ess_plot / (trace1 + trace2 +   plot_layout(guides="collect") & theme(legend.position = "top")) +
#   plot_annotation(tag_levels="A") 
# 
# ggsave("mcmc_evaluate.png",width=6.5,height=4.5)

knitr::include_graphics("mcmc_evaluate.png",dpi = 300)

```

## Model Validity {-}

While employing a measurement model ensures robustness to arbitrary data coding errors, it is still necessary to validate the model's over-time process, which imposes some assumptions on how policy activity scores change over time. The use of a random walk implies that policy differences will be relatively stable from one day to the next, which could limit the ability of scores to encompass quick, discontinuous changes [@reunig2019]. While we employ this particular specification because it has been applied previously to a variety of empirical phenomena and because of its relative parsimony, we can partially test for whether it captures changes by estimating a static IRT model for each day in the sample. The corresponding estimates represent cross-sections without any time process imposed. 

Due to the complexity of comparing the estimates, we plot the results for six countries separately in Figure 4. This figure shows that indeed the cross-sectional estimates can show much more discontinuous jumps, though we note at the same time that there appears to be substantial noise in the estimates as they only incorporate information available at a single day. Nonetheless, while the random-walk estimates certainly exhibit less discontinuous change, they do still allow for very quick divergence in policy activity scores, with France and Russia moving from the bottom to the top of the index in the space of only a few weeks. 

```{r timeest,fig.cap="Comparison of Cross-sectional Estimates of Policy Activity Scores to the Random-Walk Time Series Estimates", fig.show='hide'}

# load all of the individual estimates, combine and plot vis-a-vis AR1 model

all_mod_files <- list.files("../../data/cluster/all_iter",full.names = T)

get_est_sum2 <- get_est %>%
            ungroup %>%
  filter(country!="Chad") %>%
            mutate(estimate=plogis(estimate)*100,
                   date_announced=ymd(as.character(date_announced))) %>%
  group_by(country,date_announced) %>%
  summarize(med_est=median(estimate),
            high_est=quantile(estimate,.95),
            low_est=quantile(estimate,.05)) %>%
  group_by(date_announced) %>%
  mutate(`Country Rank`=rank(med_est))

cross_sect <- lapply(all_mod_files, function(f) {
  this_mod <- readRDS(f)

est_mod <- as.data.frame(this_mod@stan_samples,"L_full") %>%
  mutate(iter=1:n()) %>%
  gather(key="parameter",value="estimate",-iter) %>%
  mutate(date_announced=ymd(str_extract(f,"20[0-9]+-[0-9]+-[0-9]+")),
         estimate=plogis(estimate)*100,
         country=as.numeric(str_extract(parameter,"[1-9][0-9]?[0-9]?0?(?=\\])")),
         country=factor(country,labels=levels(this_mod@score_data@score_matrix$person_id))) %>% 
  group_by(country,date_announced) %>% 
  summarize(med_est2=median(estimate),
            high_est2=quantile(estimate,.95),
            low_est2=quantile(estimate,.05))

  est_mod

}) %>% bind_rows

# merge

merge_est <- left_join(get_est_sum2,cross_sect,by=c("country","date_announced"))

# let's just plot these relative to the other estimates

robust_plot <- cross_sect  %>%
  ggplot(aes(y=med_est2,x=date_announced)) +
  #geom_ribbon(aes(ymin=low_est,ymax=high_est,group=country),alpha=0.2) +
  geom_line(aes(group=country,colour=med_est2),alpha=0.7, size = 1) +
  scale_color_distiller(palette="Reds",direction=1) +
  theme_minimal() +
  theme(panel.grid = element_blank()) +
  xlab("") +
  ylab("Policy Activity Index Scale (0 to 100)") +
  guides(color="none")

#robust_plot + overall

compare_plot <- merge_est %>% 
  gather(key="est_type",value="med_est",med_est,med_est2) %>% 
  mutate(est_type=recode(est_type,`med_est`="Random Walk",
                         `med_est2`="Cross Sections")) %>% 
  filter(country %in% c("United States of America","South Korea","France","Germany","Mexico","Russia")) %>% 
  ggplot(aes(y=med_est,x=date_announced)) +
  #geom_ribbon(aes(ymin=low_est,ymax=high_est,group=country),alpha=0.2) +
  geom_line(aes(group=est_type,colour=est_type),alpha=0.7, size = 1) +
  scale_color_brewer(type="qual") +
  #scale_color_distiller(palette="Reds",direction=1) +
  theme_minimal() +
  theme(panel.grid = element_blank()) +
  xlab("") +
  ylab("Policy Activity Index Scale (0 to 100)") +
 # labs(caption = "Each cross-sectional model was re-fitted to each day's data independently using MCMC.\nHigh #variance in cross-sectional estimates is a result of limited data per day and\ndistortion due to latent scaling #effects.") +
  guides(color=guide_legend(title="")) +
  facet_wrap(~country)+ 
  theme(legend.position="bottom")

compare_plot

ggsave("Figure4.jpg", width = 180, height = 200, units = 'mm', dpi = 300)

```


We note as well that the model is parameterized so that each country has its own variance parameter. This permits the rate of change to vary by country, reducing the concern that the model may be overly restricting change. These variance parameters are shown in Figure 5, sorted in order of increasing over-time variance. These estimates are themselves substantively interesting, as the United States, which was used as the reference category, has actually one of the lowest rates of over-time change, while some countries like New Zealand, Spain and San Marino witnessed the highest variance in policy activity scores. Because, at this time, the index only captures increasing numbers of policies, the variance parameters can be given the interpretation of which countries responded in the shortest period of time across a broad array of policy indicators.

```{r plotvar,fig.height=11,fig.width=5,fig.cap="Country-level Variance (Over-time Change) Parameters from Policy Activity Index Estimation", fig.show='hide'}
# severity_fit <- readRDS("../data/activity_fit_rw.rds")
# 
# all_lev <- as.character(unique(clean_data$init_country))
# 
# get_var <- as.data.frame(severity_fit@stan_samples,"time_var_full") %>%
#   mutate(iter=1:n()) %>%
#   gather(key="parameter",value="estimate",-iter) %>%
#   mutate(date_announced=ymd(str_extract(f,"20[0-9]+-[0-9]+-[0-9]+")),
#          estimate=estimate,
#          country=as.numeric(str_extract(parameter,"[1-9][0-9]?[0-9]?0?(?=\\])")),
#          country=factor(country,labels=levels(this_mod@score_data@score_matrix$person_id))) %>%
#   group_by(country,date_announced) %>%
#   summarize(med_est2=median(estimate),
#             high_est2=quantile(estimate,.95),
#             low_est2=quantile(estimate,.05))
# 
# saveRDS(get_var,"../data/get_var.rds")

get_var <- readRDS("../../data/get_var.rds")

set.seed(27)
get_var$select = ifelse(1:194 %in% unique(c(1, 123, sample(1:194, 63))), 1, 0)
 
get_var %>% 
  ggplot(aes(y=med_est2,x=reorder(country,med_est2))) +
  geom_linerange(aes(ymin=low_est2,
                      ymax=high_est2),alpha=0.3,colour="blue") +
  geom_point(alpha=0.5,colour="blue") +
  geom_text_repel(
    data = subset(get_var, select ==1),
    aes(label=country),size=3,force=3,segment.alpha=0.5,hjust=1) +
  theme(panel.grid = element_blank(),
        panel.background = element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  coord_flip() +
  xlab("") +
  ylab("Over-Time Variance of Latent Scale") #+
  #labs(caption="Each estimate is the country-specific variance (heteroskedasticity) parameter reflecting the #average amount of over-time\nchange in the estimates. Scale is the original (logit) scale.")
ggsave("Figure5.jpg", width = 88, height = 220, units = 'mm', dpi = 300)

```





<!-- 
\begin{table}[!h]
\centering
\caption{Inter-Coder Reliability Measures for On-Going Validation}
\label{tab:validation}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccc}
\hline
\textbf{Policy} & \multicolumn{1}{c}{\textbf{(n)}} & \multicolumn{1}{c}{\textbf{Percentage Agreement}} & \multicolumn{1}{c}{\textbf{Cohen's Kappa (k)}} \\ \hline
Restrictions of Mass Gatherings & 21 & 95.2 & 0.95 \\
Closure of Schools & 14 & 92.9 & 0.92 \\
Restriction of Non-Essential Businesses & 19 & 89.5 & 0.89 \\
External Border Restrictions & 52 & 84.6 & 0.83 \\
Curfew & 6 & 83.4 & 0.82 \\
Internal Border Restrictions & 11 & 81.8 & 0.80 \\
Declaration of National Emergency & 19 & 73.7 & 0.71 \\
Quarantine/Lockdown & 28 & 67.9 & 0.65 \\
Health Measures & 52 & 65.4 & 0.63 \\
Restriction of Non-Essential Government Services & 16 & 62.5 & 0.59 \\
New Task Force, Bureau or Administrative Configuration & 9 & 55.6 & 0.52 \\
Public Awareness Measures & 15 & 53.3 & 0.49 \\
Social Distancing & 14 & 42.9 & 0.38 \\
 &  &  &  \\
 \hline
 \hline
 &  &  &  \\
\textbf{Summary Inter-coder Reliability Scores} &  &  &  \\
Percentage Agreement & \multicolumn{1}{c}{0.74} & &  \\
Cohen's Kappa & \multicolumn{1}{c}{0.72} & & \multicolumn{1}{l}{} \\
Krippendorff's alpha & \multicolumn{1}{c}{0.71} & & \multicolumn{1}{l}{} \\
Scott's PI -- Estimate (SE) & \multicolumn{1}{c}{0.71 (0.03)} & & \\ 
 &  & & \\
\hline \hline
\end{tabular}
}
\end{table}
-->


\newpage
## Data Availability {-}

For the most current, up to date version of the dataset, please visit http://coronanet-project.org or our Github page at https://github.com/saudiwin/corona_tscs. For more information on the exact variables collected, please see our publicly available  [codebook here](https://docs.google.com/document/d/1zvNMpwj0onFvUZ_gLl4RRjqS-clbHv3TIX6EOHofsME/edit?usp=sharing) and visit our [website](https://coronanet-project.org/).

## Code Availability {-}

Interested readers may also find our code for collecting the data and maintaining the database at our Github page: https://github.com/saudiwin/corona_tscs.  

\newpage


# References{-}
<div id="refs"></div>



\newpage
## Acknowledgements {-}

We deeply thank the very large number of research assistants who coded this data. Their affiliations and vita are listed in Supplementary Table 1.  Our research assistants include:

Abdelaziz Ibn Abdelouahab, Abhyudaya Tyagi, Adel Clemonds, Adriana Poppe, Advait Arya, Alette Mengerink, Alexander Pachanov, Alexandra Michaelsen, Alisa Udodik, Amadeus Albrecht, Amanda Panella, Ana Acero, Ana Belén Perianes, Anabella McElroy, Anastasia Steinbrunner, Andreas Duncan, Andres Lopez Schrader, Anelia Petrova, Angad Johar, Angela Herz, Angeline Kanyangi, Anke Horn, Anna Sophia Körner, Annika Kaiser, Anoushka Thakre, Antonia Pérez, Ariana Barrenechea, Arianna Schouten, Avery Edelman, Aysina Maria, Babrik Kushwaha, Barbora Bromová, Beatrice Di Giulio, Beatrice von Braunschweig, Bedirhan Selvi, Bianca Grizhar, Bohee Lee, Borja Arrue-Astrain, Brahim Ouerghi, Brian Chesney Quartey, Bruno Ciccarini, Calvin Kaleel, Cara Kim, Caress Schenk, Carl Philip Dybwad, Carlos Velez, Carly Kimmett, Carmen Alija, Caroline Beale, Carrie Anderson, Charlotte Vorbauer, Cheng-Hao SHEN, Chloë Fraser, Christopher Ekengren, Cornelia Marie Dybwad, Cory Martin, Csilla Horvath, Dan Downes, Dan Wu, Daniel Acosta Stasiukynas, Daniel Boey, Daniel Martínek, Dao Nguyen, Dariga Abilova, Davit Jintcharadzé, Deborah Agboola, Dick Paul Ouko, Diego Calvo, Dina Shallal, Dominik Juling, Dominik Obeth, Donia Kamel, Dorian Quelle, Dotrus Wilstic, Dovile Jankunaite, Dr Michelle King-Okoye, Dylan Ollivier, Eduardo Landaeta, Elaine Lin, Elfriede Derrer-Merk, Elisa Seith, Elizabeth Jones, Ella Pettersen, Elliot Weir, Emily Jacobo, Emma Hutchinson, Eric Repetto, Eric Walczyk, Esther Ollivier, Eugene Kwizera, Evan Parker, Ewan Lewis, Fabienne Lind, Fabio Kadner, Fadhilah Fitri Primandari, Farah Sadek, Feifei Wang, Felix Willuweit, Fernanda Werneck, Francesco Bono, Francis Yoon, Frank Yuxuan Sun, Franziska Nguyen, Frederic Denker, Gabriel Belmino Freitas, Gloria Mutheu, Godfrey Katiambo, Griffyne Makaoko, Ha-Neul Yu, Hafsa Ahmed, Hajar Chams Eddine, Hannah Shepard-Moore, Helene Paul, Helwan Felappi, Heman Asibuo, Henry Okwatch, Hibah Haider, Ian Rebouças Batista, Ilona Koch, Imogen Rickert, Ines Böhret, Ingeborg Sæle Helland, Ingrid Ravnanger, Iñigo Aldama, Isabel Conti, Isabela Russo, Isabelle Smith, Ismail Jamai Ait Hmitti, Jack Kubinec, Jakob Berg, Jane Murutu, Janet Li, Janice Klaiber, Janne Luise Piper, Jasmina Sowa, Jay Patel, Jean von Agris, Jennifer Noguera Barrera, Jessica Johansson, Jiho Yoo, Joana Lencastre Morais, Joao Lucas Dziekan R. Hilger, Joel Gräff, Johannes Kleinknecht, Jonas Bürkner, Jonas Pollig, Josef Montag, Joshua Diversi, Jule Scholten, Julia Dröge, Julia Nassl, Julia Smakman, Julia Wießmann, Kadriye Nisa Başkan, Kai Su, Karina Lisboa Båsund, Karlotta Schultz, Katharina Klaunig, Kayla Schwoerer, Khoa Tran, Klea Vogli, Kojo Vandyck, Konstanze Schönfeld, Kristian Burghartz, Laura Cadena, Laura Williamson, Laureen Hannig, Laurent Frick, Lea Clara Frömchen-Zwick, Lea Wiedmann, Lena Kolb, Leon Kohrt, Leonie Imberger, Li Cheng, Lilli Tabea Albrecht, Lily Zandstra, Lincoln Dow, Linlin Chen, Lionel Illert, Lucas Belmino Freitas, Lucia Linares, Luise Modrakowski, Lya Cuéllar, Magdalena Strebling, Maheen Zahra, Maira Sheikh, Maisa Nasirova, Maite Spel, Malina Winking, Mamle Akosua Kwao, Mara Förster, Maria (Mary) Papageorgiou, Marianne Sievers, Marius Deierl, Marlies Hofmann, Mary Nussbaumer, Maryam AlHammadi, Mascha Hotopp, Mats Jensen, Matthew Cottrell, Matthew Hargreaves, Matthew Tan, Maximilian Dirks, Maya Rollberg, Maya Sugden, Mehdi Bhouri, Michaela Balluff, Milan Chen, Milos Moskovljevic, Miranda Tessore Janowski, Miriam Witte, Mirjam Muller, Mona Horn, Muhammad Masood, Muhannad Alramlawi, Museera Moghis, Mustafa Nasery, Nadja Grossenbacher, Naela Elmore, Natalia Filkina-Spreizer, Nathan Ruhde, Nazerke Mukhlissova, Nicolas Göller, Nicole Oubre, Nida Hasan, Niklas Fent, Niklas Illenseer, Nikolina Klatt, Nivedita Darshini Bholah, Noah Fröhlich, Noelle Kubinec, Noor Altunaiji, Océane Mauffrey, Oketch Juliet Anyango, Oliver Pollex, Oliver Weber, Olivia Renda, Olzhas Gibatov, Omer Syed, Ongun Durhan, Onurhan Pehlivanoglu, Oscar Courtier, Pablo Robles, Paula Germana, Perle Chen, Philipp Weber, Pia Bansagi, Prabha Neupane, Racha Hanine, Rachel Dada, Rahman Demirkol, Raquel Karl, Rebecca Beigel, Reem Al-Ameri, Ricardo Buitrago, Richmond Silvanus Baye, Robin Fischer, Rosana Fayazzadh, Roxana Pollack, Ruohan Wang, Saif Khan, Salma Soliman, Samantha Law, Samantha Reinard, Sana Moghis, Santiago Torres Hernandez, Sarah Edmonds, Sarah Sleigh, Sau Kan Chan, Sean-Michael Pigeon, Seung-A Paik, Shalini Corea, Shruti Shukla, Shubham Sanjay Thosar, Simon Hüttemann, Sonja Müller, Sophia Tomany, Stefanie Mallow, Stella Dold, Su Ülkenli, Surendra Belbase, Symrun Razaque, Tamara White, Tanja Matheis, Tara Goodsir, Tasia Wagner, Temur Davronov, Tess de Rooij, Tess Martin, Tilda Nilsson Gige, Tom Seiler, Tristan Brömsen, Ugochukwu Okoye, Ursela Barteczko, Vanessa Cheng, Vellah Kedogo Kigwiru, Veronica Velasquez Mesa, Veronika Bartáková, Victor Abuor, Victor Pedrero, Victoria Atanasov, Vida Han, Viggo Kalandaridis, Vinayak Rajesekhar, Wencong Ruan, Winrose Njuguna, Xian Jin, Yifei Zhu, Yoes C. Kenawas, Zhandos Ybrayev.
&nbsp;
&nbsp;

We also thank Brandon Rose and Jataware for making the news database available to this project. We thank Tim Büthe, Tobias Rommel, the Chair for International Relations, the Hochschule für Politik at the Technical University of Munich (TUM), as well as the TUM School of Governance, and the TUM School of Management for the many ways they have supported this project. We further thank the Chair of International Relations, the Hochschule für Politik, and New York University Abu Dhabi for their funding in support of this endeavor. Moreover, we appreciate the support by Slack Technologies and RStudio Inc. who provided access to their technical infrastructure.


## Author Contributions {-}

All authors contributed to the supervision of the project, project administration and the writing of the paper. Additionally: C.C. contributed to the conceptualization (lead), software, data curation, visualization and funding acquisition of the project. J.B. contributed to the conceptualization, validation (lead), formal analysis and funding acquisition of the project. A.H. contributed to the validation (lead) and formal analysis of the project. R.K. contributed to the conceptualization, software, formal analysis (lead), data curation, visualization, and funding acquisition of the project. L.M. contributed to the conceptualization, software, visualization, project administration (lead) and funding acquisition of the project.

## Competing interests {-}

The authors declare no competing interests.

## Figure Legends {-}
+ Figure 1: Cumulative Incidence of Policy Event Types Over Time. This figure shows the cumulative incidence of the 16 broad policy types operationalized in the CoronaNet dataset over time.

+ Figure 2: Network Map of Bans on Inbound Flights by four European countries as of March 15, 2020. This figure shows a network of bans on inbound flights initiated by four European countries (Italy, Greece, Albania and Romania) as of March 15, 2020. 

+ Figure 3: CoronaNet Time-Varying Index of National Policy Activity of Measures in Response to COVID-19 Pandemic. Estimates are derived from Stan, a Markov Chain Monte Carlo sampler. Median posterior estimates are shown. Plot A shows the full distribution of countries, while plot B shows each month separately with the top 3 countries for that month in terms of increases in activity scores from start of the month to the end of the month.

+ Figure 4: Comparison of Cross-sectional Estimates of Policy Activity Scores to the Random-Walk Time Series Estimates. This figure provides a comparison of cross-sectional estimates of policy activity scores to the random-walk time series estimates. Each cross-sectional model was re-fitted to each day's data independently using MCMC. High variance in cross-sectional estimates is a result of limited data per day and distortion due to latent scaling effects.

+ Figure 5: Country-level Variance (Over-time Change) Parameters from Policy Activity Index Estimation. This figure shows the country-level variance (over-time change) parameters from the estimation of the policy activity index. Each estimate is the country-specific variance (heteroskedasticity) parameter reflecting the average amount of over-time change in the estimates. Scale is the original (logit) scale.

+ Extended Data Figure 1: Network Map of Bans on Inbound Flights of all European countries as of March 15, 2020. This figure shows a network of bans on inbound flights initiated by all European countries as of March 15, 2020. 

+ Extended Data Figure 2: Convergence Diagnostics for Random-Walk HMC Fit. Plot A shows the distribution of split-Rhat values for all 40,000 parameters in the model, revealing most parameters are close to 1, which indicates strong convergence. The effective number of samples for parameters in plot B is also very high, often exceeding the total number of posterior draws. Plots C and D show strong mixing across chains for the intercept and over-time parameter for the United States for January 30th.


## Tables {-}

```{r desctab2}


clean_data %>%
  
  # need to fix this in qualtrics
   mutate(target_country = ifelse(type %in% c('Closure and Regulation of Schools',
                                             'Closure of Schools',
                                             'Restriction of Non-Essential Businesses', 
                                             'Restriction and Regulation of Businesses') & grepl('All countries', target_country), country, target_country))%>%
  mutate( type=recode(type,
                      `Other Policy Not Listed Above`="Other",
                      `Quarantine` = "Quarantine/Lockdown",
                      `Closure and Regulation of Schools` = "Closure of Schools",
                      `Restriction and Regulation of Businesses` = "Restriction of Non-Essential Businesses",
                      `Restriction and Regulation of Government Services` = "Restriction of Non-Essential Government Services"
                      #`New Task Force, Bureau or Administrative Configuration`="New Task Force"
  )) %>%
  group_by(type, country) %>% 
dplyr:::summarize(numPolicies=n(),
                    numCountries=length(unique(country)),
                    target_country = ifelse(any(grepl('All countries', target_country)),
                                            205, 1+ length(unique(unlist(str_split(target_country[-which(is.na(target_country))], ','))))),
                    percEnf =mean(grepl(x=compliance,pattern="Mandatory")*100,na.rm=T)) %>%
  ungroup() %>%
  select(Type="type",everything()) %>% 
  group_by(Type) %>%
  dplyr:::summarize(`Total Number of Policies` = sum(numPolicies),
                    `Number of Countries` =  sum(numCountries),
                    `Average Number of Targeted Countries`= round(mean(target_country)),
                    `% With Mandatory Enforcement` = round(mean(percEnf))) %>%
  arrange(desc(`Total Number of Policies`)) %>%
  knitr::kable("latex",booktabs=T,
               caption="Descriptive Information about the CoronaNet Government Response Dataset") %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>%
  column_spec(1,width="4cm") %>%
  column_spec(2:5,width="2.5cm")

```


```{r rankcount2}

# out_items <- summary(severity_fit,pars="items") %>%
#   filter(`Item Type`=="Non-Inflated Discrimination")
# 
# saveRDS(out_items,'../data/out_items.rds')

out_items <- readRDS("../../data/out_items.rds")

out_items %>% 
  mutate(`Item Name`=recode(`Item Name`, `Closure of Schools`="All Schools",
                `Closure of Schools_type_highered`="Higher Ed Closure",
                `Closure of Schools_type_preschool`="Pre-school Closure",
                `Closure of Schools_type_primaryschool`="Primary School Closure",
                `Closure of Schools_type_secondschool`="High School Closure",
                `Curfew_`="Curfew",
                `Declaration of Emergency_`="Declaration of Emergency",
                `External Border Restrictions_`="External Border Closure",
                `External Border Restrictions_Other External Border Restriction`="Other Border Restriction",
                `External Border Restrictions_health_cert`="Border Health Certificates",
                `External Border Restrictions_travel_hist`="Travel History Required",
                `External Border Restrictions_Visa restrictions (e.g. suspend issuance of visa)`="Suspend Visa Issuance",
                `Health Monitoring_`="Monitoring Population Health",
                `Health Resources_`="Other Health Resources",
                `Health Resources_Doctors`="Mobilization of Doctors",
                `Health Resources_health_research`="Biomedical Research",
                `Health Resources_Hospitals`="Supporting Hospitals",
                `Health Resources_Nurses`="Mobilization of Nurses",
                `Health Resources_other_facilities`="Other Health Facilities",
                `Health Resources_Personal Protective Equipment`="PPE Mobilization",
                `Health Resources_public_tests`="Public Testing Mobilization",
                `Health Resources_quar_facility`="Building Quarantine Facilities",
                `Health Resources_Unspecified Health Infrastructure`="Other Health Facilities",
                `Health Resources_ventilators`="Mobilization of Ventilators",
                `Health Resources_volunteers`="Mobilization of Volunteers",
                `External Border Restrictions_type_screenings`="Border Health Screenings",
                `Health Resources`="General Health Resources",
                `Health Testing_`="Mobilization of Testing",
                `Internal Border Restrictions_`="Internal Border Restrictions",
                `Public Awareness Measures_`="Public Awareness Measures",
                `New Task Force, Bureau or Administrative Configuration_`="Task Force",
                `Quarantine/Lockdown_`="Quarantine/Lockdown",
                `Quarantine/Lockdown_hotel_quar`="Quarantine in Hotel",
                `Quarantine/Lockdown_Other Quarantine`="Other Quarantine",
                `Restriction of Non-Essential Businesses_`="Restriction Other Business",
                `Restriction of Non-Essential Businesses_type_commerce`="Restriction Commercial Business",
                `Restriction of Non-Essential Government Services_`="Restriction Government Services",
                `Restrictions of Mass Gatherings_`="Restriction of Mass Gatherings",
                `Social Distancing_`="Social Distancing",
                `Health Resources_type_health_masks`="Masks Policies",
                `Health Resources_type_health_other`="Other Health Resources",
                `Health Resources_type_health_staff`="Other Health Staff",
                `Health Resources_type_sanitizer`="Sanitizer Policies",
                `Health Resources_type_temporary`="Temporary Medical Units",
                `Health Resources_type_testing`="Test Production",
                `Quarantine/Lockdown`="Other Quarantines",
                `Quarantine/Lockdown_type_govt_quar`="Quarantine in Govt. Facility",
                `Quarantine/Lockdown_type_quar_restrict`="Limited Quarantine",
                `Quarantine/Lockdown_type_screenings`="Quarantine Screenings",
                `Quarantine/Lockdown_type_self_quarantine`="Quarantine At Home",
                `Restriction of Non-Essential Businesses`="General Business Restrictions",
                `Restriction of Non-Essential Businesses_type_bars`="Closure of Restaurants",
                `Restriction of Non-Essential Businesses_type_grooming`="Closure of Personal Grooming",
                `Restriction of Non-Essential Businesses_type_retail`="Closure of Retail Stores",
                `Restriction of Non-Essential Businesses_type_shopping`="Closure of Shopping Malls")) %>% 
  select(Policy="Item Name",`5% Low Estimate`="Low Posterior Interval",
         `Median Estimate`="Posterior Median",
         `95% High Estimate`="High Posterior Interval") %>%
  mutate(`Median Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `Median Estimate`*-1,
                                  `Median Estimate`),
         `5% Low Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `5% Low Estimate`*-1,
                                  `5% Low Estimate`),
         `95% High Estimate`=ifelse(Policy=="Closure of Restaurants",
                                  `95% High Estimate`*-1,
                                  `95% High Estimate`)) %>% 
  arrange(desc(`Median Estimate`)) %>%
  mutate_at(c("5% Low Estimate","Median Estimate","95% High Estimate"),~round(.,1)) %>%
    knitr::kable("latex",booktabs=T,longtable=T,
               caption="Discrimination of Item Parameters (Policies) in Policy Activity Index") %>%
  kable_styling(latex_options = c("striped", "hold_position"),font_size = 9) %>%
  column_spec(1,width="4cm") %>%
  column_spec(2:5,width="2.5cm")
```

\begin{table}[!ht]
\centering
\caption{Inter-Coder Reliability Measures for On-Going Validation}
\label{tab:validation}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccc}
\hline
\textbf{Policy} & \multicolumn{1}{c}{\textbf{(n)}} & \multicolumn{1}{c}{\textbf{Percentage Agreement}} & \multicolumn{1}{c}{\textbf{Cohen's Kappa (k)}} \\ \hline
Restrictions of Mass Gatherings & 21 & 95.2 & 0.95 \\
Closure of Schools & 14 & 92.9 & 0.92 \\
Restriction of Non-Essential Businesses & 19 & 89.5 & 0.89 \\
External Border Restrictions & 52 & 84.6 & 0.83 \\
Curfew & 6 & 83.4 & 0.82 \\
Internal Border Restrictions & 11 & 81.8 & 0.80 \\
Declaration of National Emergency & 19 & 73.7 & 0.71 \\
Quarantine/Lockdown & 28 & 67.9 & 0.65 \\
Health Measures & 52 & 65.4 & 0.63 \\
Restriction of Non-Essential Government Services & 16 & 62.5 & 0.59 \\
New Task Force, Bureau or Administrative Configuration & 9 & 55.6 & 0.52 \\
Public Awareness Measures & 15 & 53.3 & 0.49 \\
Social Distancing & 14 & 42.9 & 0.38 \\
 &  &  &  \\
 \hline
 \hline
 &  &  &  \\
\textbf{Summary Inter-coder Reliability Scores} &  &  &  \\
Percentage Agreement & \multicolumn{1}{c}{0.74} & &  \\
Cohen's Kappa & \multicolumn{1}{c}{0.72} & & \multicolumn{1}{l}{} \\
Krippendorff's alpha & \multicolumn{1}{c}{0.71} & & \multicolumn{1}{l}{} \\
Scott's PI -- Estimate (SE) & \multicolumn{1}{c}{0.71 (0.03)} & & \\ 
 &  & & \\
\hline \hline
\end{tabular}
}
\end{table}
\pagebreak












